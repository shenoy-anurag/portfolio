<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="theme-color" content="#663399"/><meta data-react-helmet="true" name="twitter:description" content="My personal website"/><meta data-react-helmet="true" name="twitter:title" content="Hindi (Devanagari Script) Digit Recognizer using Convolutional Neural Networks | Anurag Shenoy&#x27;s Blog"/><meta data-react-helmet="true" name="twitter:creator" content="Anurag Shenoy"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" property="og:description" content="My personal website"/><meta data-react-helmet="true" property="og:title" content="Hindi (Devanagari Script) Digit Recognizer using Convolutional Neural Networks | Anurag Shenoy&#x27;s Blog"/><meta data-react-helmet="true" name="description" content="My personal website"/><meta name="generator" content="Gatsby 4.12.1"/><style data-href="/styles.00bbf464be3b3b2f46f6.css" data-identity="gatsby-global-css">@import url(https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Open+Sans&display=swap);@import url(https://fonts.googleapis.com/css2?family=Anonymous+Pro&display=swap);@import url(https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap);code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#ccc;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;line-height:1.5;-o-tab-size:4;tab-size:4;text-align:left;white-space:pre;word-break:normal;word-spacing:normal}pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#2d2d2d}:not(pre)>code[class*=language-]{padding:.1em}.token.block-comment,.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#999}.token.punctuation{color:#ccc}.token.attr-name,.token.deleted,.token.namespace,.token.tag{color:#e2777a}.token.function-name{color:#6196cc}.token.boolean,.token.function,.token.number{color:#f08d49}.token.class-name,.token.constant,.token.property,.token.symbol{color:#f8c555}.token.atrule,.token.builtin,.token.important,.token.keyword,.token.selector{color:#cc99cd}.token.attr-value,.token.char,.token.regex,.token.string,.token.variable{color:#7ec699}.token.entity,.token.operator,.token.url{color:#67cdcc}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.token.inserted{color:green}.card{align-items:center;background-position:50%;background-repeat:no-repeat;background-size:cover;display:flex;height:250px;justify-content:center;overflow:hidden!important;width:100%}.card .content{cursor:pointer;font-family:Open Sans;opacity:0;padding:10px;text-align:center;-webkit-transform:translateY(20px);transform:translateY(20px);transition:all .5s ease-in-out}.card .content h1{color:#fff;font-size:28px}.card .content p{color:#fff;font-size:16px;margin-bottom:20px}.card .content .btn{background-color:#000;color:#fff;padding:10px;text-decoration:none}.card .content:hover{opacity:1;-webkit-transform:translate(0);transform:translate(0)}.navbar-wrapper{align-items:center;display:flex;justify-content:space-between;margin-top:10vh;width:80vw}.navbar-wrapper .name{font-weight:600}.navbar-wrapper .home{background-color:transparent;border:0;cursor:pointer;font-family:Open Sans;outline:none;padding:10px;text-decoration:none}.navbar-wrapper .active{color:#000}.navbar-wrapper .links-wrapper button{background-color:transparent;border:0;cursor:pointer;font-family:Open Sans;font-size:12px;opacity:.6;outline:none;padding:10px;text-decoration:none;transition:all .2s ease-in-out}.navbar-wrapper .links-wrapper button:hover{opacity:1}.navbar-wrapper .links-wrapper .link{background-color:transparent;border:0;cursor:pointer;font-family:Open Sans;font-size:12px;opacity:.6;outline:none;padding:10px;text-decoration:none;transition:all .2s ease-in-out}.navbar-wrapper .links-wrapper .link:hover{opacity:1}.navbar-wrapper .links-wrapper .active{color:#000}.header-wrapper{align-items:center;display:flex;flex-direction:column;margin-top:10vh;width:80vw}.header-wrapper h2{font-size:1rem;text-align:center}@media (min-width:320px) and (max-width:424px){.header-wrapper h2{font-size:14px}}@media (min-width:425px) and (max-width:767px){.header-wrapper h2{font-size:16px}}@media (min-width:768px) and (max-width:1023px){.header-wrapper h2{font-size:16px}}.header-wrapper .heading-wrapper h1{font-size:4rem;text-align:center}@media (min-width:320px) and (max-width:424px){.header-wrapper .heading-wrapper h1{font-size:1.5rem}}@media (min-width:425px) and (max-width:767px){.header-wrapper .heading-wrapper h1{font-size:1.5rem}}@media (min-width:768px) and (max-width:1023px){.header-wrapper .heading-wrapper h1{font-size:2.5rem}}.header-wrapper p{overflow:hidden;text-align:center;width:50%}@media (min-width:320px) and (max-width:424px){.header-wrapper p{font-size:12px;width:100%}}@media (min-width:425px) and (max-width:767px){.header-wrapper p{font-size:12px;width:100%}}@media (min-width:768px) and (max-width:1023px){.header-wrapper p{font-size:14px;width:100%}}.work-wrapper{align-items:center;display:flex;flex-direction:column;margin-top:10vh;width:80vw}.work-wrapper h1{font-size:3rem;line-height:20px}.work-wrapper .grid{grid-gap:10px;display:grid;grid-template-columns:repeat(3,1fr);margin-top:20px}@media (min-width:320px) and (max-width:424px){.work-wrapper .grid{grid-template-columns:1fr}}@media (min-width:425px) and (max-width:767px){.work-wrapper .grid{grid-template-columns:1fr}}@media (min-width:768px) and (max-width:1023px){.work-wrapper .grid{grid-template-columns:1fr 1fr}}.about-section{display:flex;justify-content:space-between;margin-top:10vh;width:80vw}@media (min-width:320px) and (max-width:424px){.about-section{flex-direction:column-reverse}}@media (min-width:425px) and (max-width:767px){.about-section{flex-direction:column-reverse}}@media (min-width:768px) and (max-width:1023px){.about-section{align-items:center;flex-direction:column-reverse}}.about-section .content{width:50%}@media (min-width:320px) and (max-width:424px){.about-section .content{width:100%}}@media (min-width:425px) and (max-width:767px){.about-section .content{width:100%}}@media (min-width:768px) and (max-width:1023px){.about-section .content{width:100%}}.about-section .content h1{font-size:3rem;line-height:20px}@media (min-width:768px) and (max-width:1023px){.about-section .content h1,.about-section .content p{text-align:center}}.about-section .image-wrapper{align-items:top;display:flex;justify-content:center;overflow:hidden;width:50%}@media (min-width:320px) and (max-width:424px){.about-section .image-wrapper{width:100%}}@media (min-width:425px) and (max-width:767px){.about-section .image-wrapper{width:100%}}@media (min-width:768px) and (max-width:1023px){.about-section .image-wrapper{width:100%}}.skills-container{align-items:center;display:flex;flex-direction:column;margin-top:10vh;width:80vw}.skills-container h1{font-size:3rem;line-height:20px}.skills-container .skills-grid{grid-gap:20px;display:grid;grid-template-columns:repeat(3,1fr);margin-top:50px}@media (min-width:320px) and (max-width:424px){.skills-container .skills-grid{grid-template-columns:1fr}}@media (min-width:425px) and (max-width:767px){.skills-container .skills-grid{grid-template-columns:1fr}}@media (min-width:768px) and (max-width:1023px){.skills-container .skills-grid{grid-template-columns:1fr 1fr}}.skills-container .skills-grid .skill{align-items:center;display:flex;flex-direction:column;text-align:center}.skills-container .skills-grid .skill img{height:3rem}.skills-container .skills-grid .skill p{font-size:14px}.skills-container .skills-grid .skill .beginner{color:#3d903d}.skills-container .skills-grid .skill .intermediate{color:#ef6731}.skills-container .skills-grid .skill .advanced{color:darkred}.skills-container .skills-grid .skill .expert{color:purple}.promotion-container{align-items:center;display:flex;flex-direction:column;margin-top:10vh;text-align:center;width:80vw}.promotion-container h1{font-size:3rem;line-height:20px}.footer-container{align-items:center;display:flex;flex-direction:column;margin-bottom:10vh;margin-top:10vh;width:80vw}.footer-container h1{font-size:3rem;line-height:20px}.footer-container h2{font-size:1.5rem;overflow:hidden}@media (min-width:320px) and (max-width:424px){.footer-container h2{display:none}}@media (min-width:425px) and (max-width:767px){.footer-container h2{font-size:14px}}@media (min-width:768px) and (max-width:1023px){.footer-container h2{font-size:1.2rem}}.footer-container .email-link{color:#000;font-size:1.5rem}.footer-container .social-icons{margin-top:20px}.footer-container .social-icons img{height:2rem;margin:10px}.footer-container span{margin-top:10px}.footer-container icon{color:red}html{--bg:#fff;--bg-secondary:#f1f1f1;--headings:#000;--text:#333;--links:blue;--highlight:#ffecb2;--code-text:#9d174d;--share-text:#999}.blog-wrapper{align-items:center;display:flex;flex-direction:column;margin-top:10vh;width:80vw}@media (min-width:320px) and (max-width:424px){.blog-wrapper{width:80%}}@media (min-width:425px) and (max-width:767px){.blog-wrapper{width:80%}}.blog-wrapper h1{font-size:3rem;line-height:20px}.blog-wrapper .btn{background-color:#000;color:#fff;margin-top:5vh;padding:10px 15px;text-align:center;text-decoration:none}.blog-wrapper .heavy{text-transform:uppercase}.blog-post-container{align-items:center;display:flex;flex-direction:column;height:auto;overflow:hidden;width:100vw}@media (min-width:320px) and (max-width:424px){.blog-post-container{width:80%}}@media (min-width:425px) and (max-width:767px){.blog-post-container{width:80%}}.blog-post-container .blog-post{align-items:center;display:flex;flex-direction:column;height:100%;justify-content:center;width:80%}.blog-post-container .blog-post h1{align-items:center}.blog-post-container .blog-post .blog-post-content{display:flex;flex-direction:column;font-family:Inter,-apple-system,avenir next,avenir,roboto,noto,ubuntu,helvetica neue,helvetica,sans-serif;font-size:1rem;line-height:2;margin-top:3vh;max-width:900px;width:80vw}.blog-post-container .blog-post .blog-post-content h1{font-size:3rem;line-height:20px}.post-date{color:#2a2a2a;font-size:.8em;font-weight:700;text-transform:uppercase}.token{font-family:Bitstream Vera Sans Mono,Consolas,Courier,monospace;font-size:.9rem}:not(pre)>code[class*=language-]{background-color:var(--bg-secondary);border-radius:.3em;color:var(--code-text);font-weight:700;padding:.2rem;white-space:normal}.gatsby-highlight-code-line{background-color:#1a1f35;border-left:.25em solid #f99;color:#f2f0ec;display:block;margin-left:-1em;margin-right:-1em;padding-left:.75em;padding-right:1em}.gatsby-highlight{background-color:#1a1f35;border-radius:.3em;color:#f2f0ec;margin:.5em 0;overflow:auto;padding:1em}.gatsby-highlight pre[class*=language-]{background-color:transparent;float:left;margin:0;min-width:100%;overflow:initial;padding:0}.gatsby-highlight pre[class*=language-].line-numbers{padding-left:2.8em}.blog-card{align-items:left;display:flex;flex-direction:column;margin-top:5vh;width:60vw}@media (min-width:320px) and (max-width:424px){.blog-card{width:90%}}@media (min-width:425px) and (max-width:767px){.blog-card{width:90%}}.blog-card .content{cursor:pointer;opacity:1;padding:10px;text-align:left}.blog-card .content h1{color:#0071c2;font-size:24px;line-height:24px}.blog-card .content p{color:#000;font-size:16px;margin-bottom:20px}.blog-card .content .date{color:#2a2a2a;font-size:.8em;font-weight:700;text-transform:uppercase}*{font-family:Inter,-apple-system,avenir next,avenir,roboto,noto,ubuntu,helvetica neue,helvetica,sans-serif}body{margin:0;overflow-x:hidden;overflow-y:scroll;padding:0}.section{height:auto;overflow:hidden;width:100vw}.container{align-items:center;display:flex;flex-direction:column;height:100%;justify-content:center;width:100%}.primary-btn{background-color:#000;border:0;color:#fff;cursor:pointer;font-size:16px;margin:10px;padding:10px 15px;text-decoration:none;text-transform:uppercase;transition:all .2s ease-in-out}.primary-btn:hover{-webkit-transform:scale(1.1);transform:scale(1.1)}</style><title data-react-helmet="true">Hindi (Devanagari Script) Digit Recognizer using Convolutional Neural Networks | Anurag Shenoy&#x27;s Blog | Portfolio</title><link rel="icon" href="/favicon-32x32.png?v=4a9773549091c227cd2eb82ccd9c5e3a" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link as="script" rel="preload" href="/webpack-runtime-b5a1197b4dce08032c07.js"/><link as="script" rel="preload" href="/framework-0841a708e42dbed148bb.js"/><link as="script" rel="preload" href="/app-4025e550f650b75cd59a.js"/><link as="script" rel="preload" href="/commons-9d97cb314d58da02d715.js"/><link as="script" rel="preload" href="/component---src-pages-markdown-remark-frontmatter-slug-js-069fbe32344d374724d4.js"/><link as="fetch" rel="preload" href="/page-data/blog/hindi-mnist-recognizer/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/63159454.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="section"><div class="container"><div class="navbar-wrapper"><div role="button" class="name" tabindex="0"><a class="home active" href="/">Portfolio.</a></div><div class="links-wrapper"><a class="link active" href="/work">Work</a><a class="link active" href="/blog">Blog</a><a class="link active" href="/about">About</a><button>Contact</button></div></div></div></div><main><div class="blog-post-container"><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><div class="blog-post"><h1>Hindi (Devanagari Script) Digit Recognizer using Convolutional Neural Networks</h1><p class="post-date"><span>February 24, 2022</span></p><div class="blog-post-content"><h2>Overview</h2>
<p>While trying to create an MNIST like personal project, but on Indian languages such as Hindi, Kannada or Tamil, I stumbled upon a Hindi (Devangari script) Handwritten characters dataset by Shailesh Acharya and Prashnna Kumar Gyawali, which is uploaded to the <a href="http://archive.ics.uci.edu/ml">UCI Machine Learning Repository</a>.</p>
<p>You can find the dataset here: <a href="https://archive.ics.uci.edu/ml/datasets/Devanagari+Handwritten+Character+Dataset">https://archive.ics.uci.edu/ml/datasets/Devanagari+Handwritten+Character+Dataset</a></p>
<p>This dataset contains all Devanagari characters and I only wanted to use the digit glyphs for classification, so I downloaded the complete dataset, and removed any data which was not a digit.</p>
<h2>Dataset</h2>
<p>Data Type: Grayscale Image</p>
<p>Image Format: PNG</p>
<p>Resolution: 32 x 32 pixels</p>
<p>Actual character is centered within 28 by 28 pixel, padding of 2 pixel is added on all four sides of actual character.</p>
<p>There are ~1700 images per class in the Train set, and around ~300 images per class in the Test set.</p>
<h2>Tutorial-Style Notebook</h2>
<p>You can find the full Jupyter notebook here: <a href="https://github.com/shenoy-anurag/machine-learning/blob/main/hindi-digit-recognition.ipynb">https://github.com/shenoy-anurag/machine-learning/blob/main/hindi-digit-recognition.ipynb</a></p>
<p>We begin by importing libraries which are important for our data-preprocessing, neural network building, model saving and visualization.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> pickle <span class="token keyword">as</span> pkl

<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> keras
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> image_dataset_from_directory
<span class="token keyword">from</span> keras <span class="token keyword">import</span> layers
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Tensor Flow Version: </span><span class="token interpolation"><span class="token punctuation">{</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Keras Version: </span><span class="token interpolation"><span class="token punctuation">{</span>keras<span class="token punctuation">.</span>__version__<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Tensor Flow Version: 2.7.0
Keras Version: 2.7.0</code></pre></div>
<h3>Downloading the Data</h3>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">DATA_FOLDER <span class="token operator">=</span> <span class="token string">"./data"</span>

hindi_handwritten_dataset_zip_url <span class="token operator">=</span> <span class="token string">"https://archive.ics.uci.edu/ml/machine-learning-databases/00389/DevanagariHandwrittenCharacterDataset.zip"</span>
zip_file_name <span class="token operator">=</span> hindi_handwritten_dataset_zip_url<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

TRAIN_FOLDER_NAME <span class="token operator">=</span> <span class="token string">"Train"</span>
TEST_FOLDER_NAME <span class="token operator">=</span> <span class="token string">"Test"</span>
DEVANAGARI_ZIP_PATH <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>DATA_FOLDER<span class="token punctuation">,</span> zip_file_name<span class="token punctuation">)</span>
DEVANAGARI_DATA_FOLDER <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>
    os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>DATA_FOLDER<span class="token punctuation">,</span> zip_file_name<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>DEVANAGARI_DATA_FOLDER<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">./data/DevanagariHandwrittenCharacterDataset</code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># Download the dataset and de-compress</span>
<span class="token keyword">import</span> requests
<span class="token keyword">import</span> zipfile

<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>DEVANAGARI_ZIP_PATH<span class="token punctuation">)</span><span class="token punctuation">:</span>
    req <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>hindi_handwritten_dataset_zip_url<span class="token punctuation">,</span> allow_redirects<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># Writing the file to the local file system</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>DEVANAGARI_ZIP_PATH<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> output_file<span class="token punctuation">:</span>
        output_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>req<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Downloaded zip file"</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Zip file already present"</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>DEVANAGARI_DATA_FOLDER<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span>DEVANAGARI_ZIP_PATH<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> zip_ref<span class="token punctuation">:</span>
        zip_ref<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span>DATA_FOLDER<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Extracted zip file"</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Files already present on disk"</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Zip file already present
Files already present on disk</code></pre></div>
<h3>Removing classes we don't want</h3>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">labels_to_keep <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"digit_0"</span><span class="token punctuation">,</span> <span class="token string">"digit_1"</span><span class="token punctuation">,</span> <span class="token string">"digit_2"</span><span class="token punctuation">,</span> <span class="token string">"digit_3"</span><span class="token punctuation">,</span> <span class="token string">"digit_4"</span><span class="token punctuation">,</span> <span class="token string">"digit_5"</span><span class="token punctuation">,</span> <span class="token string">"digit_6"</span><span class="token punctuation">,</span> <span class="token string">"digit_7"</span><span class="token punctuation">,</span> <span class="token string">"digit_8"</span><span class="token punctuation">,</span> <span class="token string">"digit_9"</span>
<span class="token punctuation">]</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> shutil
<span class="token keyword">import</span> glob

<span class="token comment"># We will only keep the Hindi digits in training data.</span>
folders <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>DEVANAGARI_DATA_FOLDER<span class="token punctuation">,</span> TRAIN_FOLDER_NAME<span class="token punctuation">,</span> <span class="token string">"*"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> f <span class="token keyword">in</span> folders<span class="token punctuation">:</span>
    <span class="token keyword">if</span> f<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">not</span> <span class="token keyword">in</span> labels_to_keep<span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
        <span class="token keyword">except</span> OSError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Error: %s : %s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>f<span class="token punctuation">,</span> e<span class="token punctuation">.</span>strerror<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Doing the same to test data.</span>
folders <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>DEVANAGARI_DATA_FOLDER<span class="token punctuation">,</span> TEST_FOLDER_NAME<span class="token punctuation">,</span> <span class="token string">"*"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> f <span class="token keyword">in</span> folders<span class="token punctuation">:</span>
    <span class="token keyword">if</span> f<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">not</span> <span class="token keyword">in</span> labels_to_keep<span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
        <span class="token keyword">except</span> OSError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Error: %s : %s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>f<span class="token punctuation">,</span> e<span class="token punctuation">.</span>strerror<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div>
<h3>Dataset and Model Parameters</h3>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">RANDOM_SEED <span class="token operator">=</span> <span class="token number">42</span>

<span class="token comment"># Data parameters</span>
IMG_HEIGHT <span class="token operator">=</span> <span class="token number">32</span>
IMG_WIDTH <span class="token operator">=</span> <span class="token number">32</span>
VALIDATION_SPLIT <span class="token operator">=</span> <span class="token number">0.1</span>

<span class="token comment"># Model parameters</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">32</span>
KERNEL_SIZE <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
MAX_POOLING_SIZE <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
DROPOUT <span class="token operator">=</span> <span class="token number">0.5</span>

num_classes <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>labels_to_keep<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">classes <span class="token operator">=</span> labels_to_keep
classes_to_output_class_names <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"digit_0"</span><span class="token punctuation">:</span> <span class="token string">"0"</span><span class="token punctuation">,</span> <span class="token string">"digit_1"</span><span class="token punctuation">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token string">"digit_2"</span><span class="token punctuation">:</span> <span class="token string">"2"</span><span class="token punctuation">,</span> <span class="token string">"digit_3"</span><span class="token punctuation">:</span> <span class="token string">"3"</span><span class="token punctuation">,</span> 
    <span class="token string">"digit_4"</span><span class="token punctuation">:</span> <span class="token string">"4"</span><span class="token punctuation">,</span> <span class="token string">"digit_5"</span><span class="token punctuation">:</span> <span class="token string">"5"</span><span class="token punctuation">,</span> <span class="token string">"digit_6"</span><span class="token punctuation">:</span> <span class="token string">"6"</span><span class="token punctuation">,</span> <span class="token string">"digit_7"</span><span class="token punctuation">:</span> <span class="token string">"7"</span><span class="token punctuation">,</span> 
    <span class="token string">"digit_8"</span><span class="token punctuation">:</span> <span class="token string">"8"</span><span class="token punctuation">,</span> <span class="token string">"digit_9"</span><span class="token punctuation">:</span> <span class="token string">"9"</span>
<span class="token punctuation">}</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Gathering training dataset..."</span><span class="token punctuation">)</span>
train_dataset <span class="token operator">=</span> image_dataset_from_directory<span class="token punctuation">(</span>
    os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>DEVANAGARI_DATA_FOLDER<span class="token punctuation">,</span> TRAIN_FOLDER_NAME<span class="token punctuation">)</span><span class="token punctuation">,</span>
    labels<span class="token operator">=</span><span class="token string">"inferred"</span><span class="token punctuation">,</span>
    label_mode<span class="token operator">=</span><span class="token string">"int"</span><span class="token punctuation">,</span>
    class_names<span class="token operator">=</span>classes<span class="token punctuation">,</span>
    color_mode<span class="token operator">=</span><span class="token string">"grayscale"</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span>
    image_size<span class="token operator">=</span><span class="token punctuation">(</span>IMG_HEIGHT<span class="token punctuation">,</span> IMG_WIDTH<span class="token punctuation">)</span><span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    seed<span class="token operator">=</span>RANDOM_SEED<span class="token punctuation">,</span>
    validation_split<span class="token operator">=</span>VALIDATION_SPLIT<span class="token punctuation">,</span>
    subset<span class="token operator">=</span><span class="token string">"training"</span><span class="token punctuation">,</span>
    interpolation<span class="token operator">=</span><span class="token string">"bilinear"</span><span class="token punctuation">,</span>
    follow_links<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    crop_to_aspect_ratio<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Gathering validation dataset..."</span><span class="token punctuation">)</span>
val_dataset <span class="token operator">=</span> image_dataset_from_directory<span class="token punctuation">(</span>
    os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>DEVANAGARI_DATA_FOLDER<span class="token punctuation">,</span> TRAIN_FOLDER_NAME<span class="token punctuation">)</span><span class="token punctuation">,</span>
    labels<span class="token operator">=</span><span class="token string">"inferred"</span><span class="token punctuation">,</span>
    label_mode<span class="token operator">=</span><span class="token string">"int"</span><span class="token punctuation">,</span>
    class_names<span class="token operator">=</span>classes<span class="token punctuation">,</span>
    color_mode<span class="token operator">=</span><span class="token string">"grayscale"</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span>
    image_size<span class="token operator">=</span><span class="token punctuation">(</span>IMG_HEIGHT<span class="token punctuation">,</span> IMG_WIDTH<span class="token punctuation">)</span><span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    seed<span class="token operator">=</span>RANDOM_SEED<span class="token punctuation">,</span>
    validation_split<span class="token operator">=</span>VALIDATION_SPLIT<span class="token punctuation">,</span>
    subset<span class="token operator">=</span><span class="token string">"validation"</span><span class="token punctuation">,</span>
    interpolation<span class="token operator">=</span><span class="token string">"bilinear"</span><span class="token punctuation">,</span>
    follow_links<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    crop_to_aspect_ratio<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Gathering test dataset..."</span><span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> image_dataset_from_directory<span class="token punctuation">(</span>
    os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>DEVANAGARI_DATA_FOLDER<span class="token punctuation">,</span> TEST_FOLDER_NAME<span class="token punctuation">)</span><span class="token punctuation">,</span>
    labels<span class="token operator">=</span><span class="token string">"inferred"</span><span class="token punctuation">,</span>
    label_mode<span class="token operator">=</span><span class="token string">"int"</span><span class="token punctuation">,</span>
    class_names<span class="token operator">=</span>classes<span class="token punctuation">,</span>
    color_mode<span class="token operator">=</span><span class="token string">"grayscale"</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span>
    image_size<span class="token operator">=</span><span class="token punctuation">(</span>IMG_HEIGHT<span class="token punctuation">,</span> IMG_WIDTH<span class="token punctuation">)</span><span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    seed<span class="token operator">=</span>RANDOM_SEED<span class="token punctuation">,</span>
    validation_split<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># None, so that we get all the data.</span>
    subset<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    interpolation<span class="token operator">=</span><span class="token string">"bilinear"</span><span class="token punctuation">,</span>
    follow_links<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    crop_to_aspect_ratio<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Gathering training dataset...
Found 17000 files belonging to 10 classes.
Using 15300 files for training.
Metal device set to: Apple M1
Gathering validation dataset...


2022-02-23 23:32:59.540309: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-02-23 23:32:59.540429: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined>)


Found 17000 files belonging to 10 classes.
Using 1700 files for validation.
Gathering test dataset...
Found 3000 files belonging to 10 classes.</code></pre></div>
<p>The tensorflow Dataset object automatically performs ordinal encoding on the labels and so, we are creating our own ordinal encoding and storing it in the variable <code class="language-text">labels_to_class_names</code>.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">class_names_to_labels <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>cls_name<span class="token punctuation">,</span> lbl<span class="token punctuation">)</span> <span class="token keyword">for</span> cls_name<span class="token punctuation">,</span> lbl <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>classes<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
labels_to_class_names <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> k<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> class_names_to_labels<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>labels_to_class_names<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">{0: 'digit_0', 1: 'digit_1', 2: 'digit_2', 3: 'digit_3', 4: 'digit_4', 5: 'digit_5', 6: 'digit_6', 7: 'digit_7', 8: 'digit_8', 9: 'digit_9'}</code></pre></div>
<h3>Look at the data</h3>
<p>Let us take a look at the data after it has been stored as a tensorflow tf.Data.Dataset object.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># Take a look at the input data</span>
rows <span class="token operator">=</span> <span class="token number">2</span>
columns <span class="token operator">=</span> <span class="token number">3</span>
fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
j <span class="token operator">=</span> <span class="token number">1</span>
<span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_dataset<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> l <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>images<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span>rows<span class="token punctuation">,</span> columns<span class="token punctuation">,</span> j<span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">,</span> vmin<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> vmax<span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>labels_to_class_names<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        j <span class="token operator">+=</span> <span class="token number">1</span></code></pre></div>
<p><img src="../images/hindi-mnist/output_13_2.jpg" alt="random devanagari digits"></p>
<h3>Data Augmentation and Normalisation</h3>
<h4>Normalisation</h4>
<p>The values of pixels in the images range from <code class="language-text">[0, 255]</code>.</p>
<p>We should normalize the values to be in the <code class="language-text">[0, 1]</code> range.</p>
<p>The purpose of Normalisation is to make values measured on different scales to be all "squished" or "expanded" to a common scale/range such as <code class="language-text">[0, 1]</code>.
This ensures that each variable in the data is given an equal importance and no variable influences the model parameters more than any other purely because it's values are larger.</p>
<p>We will perform the normalization using <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling"><code>tf.keras.layers.Rescaling</code></a>.</p>
<h4>Augmentation</h4>
<p>Augmenting the data allows us to ensure that the model doesn't just learn something that's common for the entire class, but has no meaning when it comes to classification.</p>
<p>For example, consider a dataset with blue cars and red cars.</p>
<p>If all the blue cars are facing to the right and all red cars are facing left, then the model will end up being influenced by the orientation of the car in the image, thus producing incorrect predications when you ask the model to predict, say, the color of a blue car facing to the left.</p>
<p>By performing augmentations such as Flipping, Rotations, Zooming, Shearing, Translations etc, we prevent the model from learning/memorizing features which are irrelevant.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># Scale images to the [0, 1] range</span>
normalization_layer <span class="token operator">=</span> layers<span class="token punctuation">.</span>Rescaling<span class="token punctuation">(</span><span class="token number">1.</span> <span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">)</span>
<span class="token comment"># Data Augmentations</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'/CPU:0'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    data_augmentation_layers <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>
            layers<span class="token punctuation">.</span>RandomZoom<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            layers<span class="token punctuation">.</span>RandomTranslation<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span>
    <span class="token punctuation">)</span></code></pre></div>
<h3>Prefetch and Caching</h3>
<p>Learn about tf.data.Dataset Prefetching here: <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch</a>
Learn about tf.data.Dataset Caching here: <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache</a></p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># prefetching and caching data to improve performance.</span>
AUTOTUNE <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>AUTOTUNE

train_ds <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span>AUTOTUNE<span class="token punctuation">)</span>
val_ds <span class="token operator">=</span> val_dataset<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span>AUTOTUNE<span class="token punctuation">)</span></code></pre></div>
<h3>Checking Data Augmentation</h3>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">rows <span class="token operator">=</span> <span class="token number">3</span>
columns <span class="token operator">=</span> <span class="token number">4</span>
<span class="token keyword">for</span> images<span class="token punctuation">,</span> _ <span class="token keyword">in</span> train_dataset<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">,</span> vmin<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> vmax<span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">)</span>
    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'/CPU:0'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            augmented_images <span class="token operator">=</span> data_augmentation_layers<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span>rows<span class="token punctuation">,</span> columns<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># plt.imshow(augmented_images[0].numpy().astype("uint8"))</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>augmented_images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">,</span> vmin<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> vmax<span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span></code></pre></div>
<p><img src="../images/hindi-mnist/output_19_0.jpg" alt="first devanagari digit"></p>
<p><img src="../images/hindi-mnist/output_19_1.jpg" alt="augmented digits"></p>
<h3>Creating the Model</h3>
<p>First, we'll add the <code class="language-text">data_augmentation_layers</code> and the <code class="language-text">normalization_layer</code>, following which we'll create a convolutional neural network.</p>
<p>Learn more about CNNs here: <a href="https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/">https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/</a></p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        data_augmentation_layers<span class="token punctuation">,</span>
        normalization_layer<span class="token punctuation">,</span>
        layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>KERNEL_SIZE<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span>MAX_POOLING_SIZE<span class="token punctuation">)</span><span class="token punctuation">,</span>
        layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>KERNEL_SIZE<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span>MAX_POOLING_SIZE<span class="token punctuation">)</span><span class="token punctuation">,</span>
        layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>DROPOUT<span class="token punctuation">)</span><span class="token punctuation">,</span>
        layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"softmax"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span></code></pre></div>
<h3>Compiling and Building Model</h3>
<p>Note that we are using Categorical Crossentropy as the loss function, and this is well suited for categorical output data.
Read more here: <a href="https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression">https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression</a></p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>
              loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>build<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span>BATCH_SIZE<span class="token punctuation">,</span> IMG_HEIGHT<span class="token punctuation">,</span> IMG_WIDTH<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential (Sequential)     (32, 32, 32, 1)           0         
                                                                 
 rescaling (Rescaling)       (32, 32, 32, 1)           0         
                                                                 
 conv2d (Conv2D)             (32, 30, 30, 32)          320       
                                                                 
 max_pooling2d (MaxPooling2D  (32, 15, 15, 32)         0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (32, 13, 13, 64)          18496     
                                                                 
 max_pooling2d_1 (MaxPooling  (32, 6, 6, 64)           0         
 2D)                                                             
                                                                 
 dropout (Dropout)           (32, 6, 6, 64)            0         
                                                                 
 flatten (Flatten)           (32, 2304)                0         
                                                                 
 dense (Dense)               (32, 128)                 295040    
                                                                 
 dense_1 (Dense)             (32, 10)                  1290      
                                                                 
=================================================================
Total params: 315,146
Trainable params: 315,146
Non-trainable params: 0
_________________________________________________________________</code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">epochs <span class="token operator">=</span> <span class="token number">15</span>
history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_dataset<span class="token punctuation">,</span>
    validation_data<span class="token operator">=</span>val_dataset<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span>epochs
<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Epoch 1/15


2022-02-23 23:33:01.336773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.


479/479 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.8952

2022-02-23 23:33:09.665198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.


479/479 [==============================] - 9s 18ms/step - loss: 0.3290 - accuracy: 0.8952 - val_loss: 0.0485 - val_accuracy: 0.9865
Epoch 2/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0899 - accuracy: 0.9727 - val_loss: 0.0420 - val_accuracy: 0.9871
Epoch 3/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0578 - accuracy: 0.9808 - val_loss: 0.0216 - val_accuracy: 0.9924
Epoch 4/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0171 - val_accuracy: 0.9935
Epoch 5/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.0191 - val_accuracy: 0.9918
Epoch 6/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0345 - accuracy: 0.9892 - val_loss: 0.0086 - val_accuracy: 0.9976
Epoch 7/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.0097 - val_accuracy: 0.9965
Epoch 8/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.0110 - val_accuracy: 0.9959
Epoch 9/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0142 - val_accuracy: 0.9953
Epoch 10/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.0104 - val_accuracy: 0.9953
Epoch 11/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0126 - val_accuracy: 0.9965
Epoch 12/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0097 - val_accuracy: 0.9971
Epoch 13/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0081 - val_accuracy: 0.9971
Epoch 14/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0321 - val_accuracy: 0.9912
Epoch 15/15
479/479 [==============================] - 8s 17ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0176 - val_accuracy: 0.9941</code></pre></div>
<h3>Measuring Performance on Training and Test Data</h3>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">acc <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span>
val_acc <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_accuracy'</span><span class="token punctuation">]</span>

loss <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span>
val_loss <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span>

epochs_range <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>

fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>lineplot<span class="token punctuation">(</span>x<span class="token operator">=</span>epochs_range<span class="token punctuation">,</span> y<span class="token operator">=</span>acc<span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token string">'brief'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Accuracy'</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>lineplot<span class="token punctuation">(</span>x<span class="token operator">=</span>epochs_range<span class="token punctuation">,</span> y<span class="token operator">=</span>val_acc<span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token string">'brief'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Validation Accuracy'</span><span class="token punctuation">)</span>

fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>lineplot<span class="token punctuation">(</span>x<span class="token operator">=</span>epochs_range<span class="token punctuation">,</span> y<span class="token operator">=</span>loss<span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token string">'brief'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Loss'</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>lineplot<span class="token punctuation">(</span>x<span class="token operator">=</span>epochs_range<span class="token punctuation">,</span> y<span class="token operator">=</span>val_loss<span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token string">'brief'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Validation Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div>
<p><img src="../images/hindi-mnist/output_26_0.jpg" alt="model metrics graph"></p>
<h3>Metrics</h3>
<table>
<thead>
<tr>
<th align="left">Data</th>
<th align="center">Accuracy</th>
<th align="right">Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Training</td>
<td align="center">99.52%</td>
<td align="right">0.0139</td>
</tr>
<tr>
<td align="left">Validation</td>
<td align="center">99.65%</td>
<td align="right">0.0107</td>
</tr>
</tbody>
</table>
<!-- Training Accuracy: 99.52%

Validation Accuracy: 99.65%

Training Loss: 0.0139

Validation Loss: 0.0107 -->
<p>We can see that the model's accuracy and validation accuracy quickly went up during and after the first epoch and then it saturated around epoch #10.</p>
<p>Training and validation loss also fell dramatically after the second epoch, and reached a saturation around epoch #11.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Evaluate"</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_dataset<span class="token punctuation">)</span>
result <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>metrics_names<span class="token punctuation">,</span> result<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Evaluate
94/94 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9953</code></pre></div>
<h3>Test Metrics</h3>
<table>
<thead>
<tr>
<th align="left">Data</th>
<th align="center">Accuracy</th>
<th align="right">Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Test</td>
<td align="center">99.56%</td>
<td align="right">0.0189</td>
</tr>
</tbody>
</table>
<h4>Overall this is a great result, and it shows that the model has generalized properly and has low variance, while having high bias.</h4>
<h3>Saving the Model</h3>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">MODEL_FOLDER <span class="token operator">=</span> <span class="token string">"./models"</span>
HINDI_MNIST_FOLDER <span class="token operator">=</span> <span class="token string">"hindi_mnist"</span>
MODEL_SAVE_FOLDER <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>MODEL_FOLDER<span class="token punctuation">,</span> HINDI_MNIST_FOLDER<span class="token punctuation">)</span>
MODEL_SAVE_PATH <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>MODEL_FOLDER<span class="token punctuation">,</span> HINDI_MNIST_FOLDER<span class="token punctuation">,</span> <span class="token string">"model.h5"</span><span class="token punctuation">)</span>
<span class="token comment"># pickle files</span>
CLASSES_PKL_FILE <span class="token operator">=</span> <span class="token string">"classes.pickle"</span>
CLASSES_PKL_PATH <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>MODEL_SAVE_FOLDER<span class="token punctuation">,</span> CLASSES_PKL_FILE<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">model<span class="token punctuation">.</span>save<span class="token punctuation">(</span>
    MODEL_SAVE_PATH<span class="token punctuation">,</span> overwrite<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> include_optimizer<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> save_format<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    signatures<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> options<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> save_traces<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>CLASSES_PKL_PATH<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    pkl<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>classes<span class="token punctuation">,</span> f<span class="token punctuation">)</span>
    pkl<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>labels_to_class_names<span class="token punctuation">,</span> f<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># Delete model and labels_to_class_names to check if we correctly saved the model by loading it from disk and re-evaluating on test data.</span>
<span class="token keyword">del</span> model
<span class="token keyword">del</span> classes
<span class="token keyword">del</span> labels_to_class_names</code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> pickle <span class="token keyword">as</span> pkl
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> load_model</code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">model <span class="token operator">=</span> load_model<span class="token punctuation">(</span>MODEL_SAVE_PATH<span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>CLASSES_PKL_PATH<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    classes <span class="token operator">=</span> pkl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    labels_to_class_names <span class="token operator">=</span> pkl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Evaluate"</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_dataset<span class="token punctuation">)</span>
result <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>metrics_names<span class="token punctuation">,</span> result<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Evaluate
19/94 [=====>........................] - ETA: 0s - loss: 0.0088 - accuracy: 0.9984

2022-02-23 23:35:04.809043: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.

94/94 [==============================] - 1s 6ms/step - loss: 0.0242 - accuracy: 0.9953
{'loss': 0.024181803688406944, 'accuracy': 0.9953333139419556}</code></pre></div>
<h2>References and Further Reading</h2>
<ol>
<li>Dataset: <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/00389/DevanagariHandwrittenCharacterDataset.zip">https://archive.ics.uci.edu/ml/machine-learning-databases/00389/DevanagariHandwrittenCharacterDataset.zip</a></li>
<li>Tensorflow Rescaling documentation <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling</a></li>
<li>Tensorflow Dataset documentation <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">https://www.tensorflow.org/api_docs/python/tf/data/Dataset</a></li>
<li>Convolutional Neural Networks: <a href="https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/">https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/</a></li>
<li>Categorical CrossEntropy loss function <a href="https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression">https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression</a></li>
<li>Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [<a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>]. Irvine, CA: University of California, School of Information and Computer Science.</li>
</ol></div></div></div></main></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/hindi-mnist-recognizer/";window.___webpackCompilationHash="081552d3c4ef2a6addac";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-65ceb1e975d78bd881ff.js"],"app":["/app-4025e550f650b75cd59a.js"],"component---src-pages-404-js":["/component---src-pages-404-js-6f7c02045c8a298582d1.js"],"component---src-pages-about-js":["/component---src-pages-about-js-3a791f9dd0d2fec8d001.js"],"component---src-pages-blog-js":["/component---src-pages-blog-js-7a39da1ff7a6a2d1f249.js"],"component---src-pages-index-js":["/component---src-pages-index-js-be5308d0d420bec004e6.js"],"component---src-pages-markdown-remark-frontmatter-slug-js":["/component---src-pages-markdown-remark-frontmatter-slug-js-069fbe32344d374724d4.js"],"component---src-pages-work-js":["/component---src-pages-work-js-036aecaa9ea7f1758396.js"]};/*]]>*/</script><script src="/polyfill-65ceb1e975d78bd881ff.js" nomodule=""></script><script src="/component---src-pages-markdown-remark-frontmatter-slug-js-069fbe32344d374724d4.js" async=""></script><script src="/commons-9d97cb314d58da02d715.js" async=""></script><script src="/app-4025e550f650b75cd59a.js" async=""></script><script src="/framework-0841a708e42dbed148bb.js" async=""></script><script src="/webpack-runtime-b5a1197b4dce08032c07.js" async=""></script></body></html>