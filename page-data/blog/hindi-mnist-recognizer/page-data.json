{
    "componentChunkName": "component---src-pages-markdown-remark-frontmatter-slug-js",
    "path": "/blog/hindi-mnist-recognizer/",
    "result": {"data":{"markdownRemark":{"html":"<h2 id=\"overview\" style=\"position:relative;\"><a href=\"#overview\" aria-label=\"overview permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Overview</h2>\n<p>While trying to create an MNIST like personal project, but on Indian languages such as Hindi, Kannada or Tamil, I stumbled upon a Hindi (Devangari script) Handwritten characters dataset by Shailesh Acharya and Prashnna Kumar Gyawali, which is uploaded to the <a href=\"http://archive.ics.uci.edu/ml\">UCI Machine Learning Repository</a>.</p>\n<p>You can find the dataset here: <a href=\"https://archive.ics.uci.edu/ml/datasets/Devanagari+Handwritten+Character+Dataset\">https://archive.ics.uci.edu/ml/datasets/Devanagari+Handwritten+Character+Dataset</a></p>\n<p>This dataset contains all Devanagari characters and I only wanted to use the digit glyphs for classification, so I downloaded the complete dataset, and removed any data which was not a digit.</p>\n<h2 id=\"dataset\" style=\"position:relative;\"><a href=\"#dataset\" aria-label=\"dataset permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Dataset</h2>\n<p>Data Type: Grayscale Image</p>\n<p>Image Format: PNG</p>\n<p>Resolution: 32 x 32 pixels</p>\n<p>Actual character is centered within 28 by 28 pixel, padding of 2 pixel is added on all four sides of actual character.</p>\n<p>There are ~1700 images per class in the Train set, and around ~300 images per class in the Test set.</p>\n<h2 id=\"tutorial-style-notebook\" style=\"position:relative;\"><a href=\"#tutorial-style-notebook\" aria-label=\"tutorial style notebook permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Tutorial-Style Notebook</h2>\n<p>You can find the full Jupyter notebook here: <a href=\"https://github.com/shenoy-anurag/machine-learning/blob/main/hindi-digit-recognition.ipynb\">https://github.com/shenoy-anurag/machine-learning/blob/main/hindi-digit-recognition.ipynb</a></p>\n<p>We begin by importing libraries which are important for our data-preprocessing, neural network building, model saving and visualization.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> pickle <span class=\"token keyword\">as</span> pkl\n\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>image <span class=\"token keyword\">import</span> image_dataset_from_directory\n<span class=\"token keyword\">from</span> keras <span class=\"token keyword\">import</span> layers\n<span class=\"token keyword\">from</span> matplotlib <span class=\"token keyword\">import</span> pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sns\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Tensor Flow Version: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>tf<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Keras Version: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>keras<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Tensor Flow Version: 2.7.0\nKeras Version: 2.7.0</code></pre></div>\n<h3 id=\"downloading-the-data\" style=\"position:relative;\"><a href=\"#downloading-the-data\" aria-label=\"downloading the data permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Downloading the Data</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">DATA_FOLDER <span class=\"token operator\">=</span> <span class=\"token string\">\"./data\"</span>\n\nhindi_handwritten_dataset_zip_url <span class=\"token operator\">=</span> <span class=\"token string\">\"https://archive.ics.uci.edu/ml/machine-learning-databases/00389/DevanagariHandwrittenCharacterDataset.zip\"</span>\nzip_file_name <span class=\"token operator\">=</span> hindi_handwritten_dataset_zip_url<span class=\"token punctuation\">.</span>rsplit<span class=\"token punctuation\">(</span><span class=\"token string\">'/'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n\nTRAIN_FOLDER_NAME <span class=\"token operator\">=</span> <span class=\"token string\">\"Train\"</span>\nTEST_FOLDER_NAME <span class=\"token operator\">=</span> <span class=\"token string\">\"Test\"</span>\nDEVANAGARI_ZIP_PATH <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>DATA_FOLDER<span class=\"token punctuation\">,</span> zip_file_name<span class=\"token punctuation\">)</span>\nDEVANAGARI_DATA_FOLDER <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>\n    os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>DATA_FOLDER<span class=\"token punctuation\">,</span> zip_file_name<span class=\"token punctuation\">.</span>rsplit<span class=\"token punctuation\">(</span><span class=\"token string\">\".\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>DEVANAGARI_DATA_FOLDER<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">./data/DevanagariHandwrittenCharacterDataset</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Download the dataset and de-compress</span>\n<span class=\"token keyword\">import</span> requests\n<span class=\"token keyword\">import</span> zipfile\n\n<span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span>DEVANAGARI_ZIP_PATH<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    req <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>hindi_handwritten_dataset_zip_url<span class=\"token punctuation\">,</span> allow_redirects<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># Writing the file to the local file system</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>DEVANAGARI_ZIP_PATH<span class=\"token punctuation\">,</span> <span class=\"token string\">'wb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> output_file<span class=\"token punctuation\">:</span>\n        output_file<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>req<span class=\"token punctuation\">.</span>content<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Downloaded zip file\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Zip file already present\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span>DEVANAGARI_DATA_FOLDER<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> zipfile<span class=\"token punctuation\">.</span>ZipFile<span class=\"token punctuation\">(</span>DEVANAGARI_ZIP_PATH<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> zip_ref<span class=\"token punctuation\">:</span>\n        zip_ref<span class=\"token punctuation\">.</span>extractall<span class=\"token punctuation\">(</span>DATA_FOLDER<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Extracted zip file\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Files already present on disk\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Zip file already present\nFiles already present on disk</code></pre></div>\n<h3 id=\"removing-classes-we-dont-want\" style=\"position:relative;\"><a href=\"#removing-classes-we-dont-want\" aria-label=\"removing classes we dont want permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Removing classes we don't want</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">labels_to_keep <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"digit_0\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_3\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_6\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_7\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_9\"</span>\n<span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> shutil\n<span class=\"token keyword\">import</span> glob\n\n<span class=\"token comment\"># We will only keep the Hindi digits in training data.</span>\nfolders <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">.</span>glob<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>DEVANAGARI_DATA_FOLDER<span class=\"token punctuation\">,</span> TRAIN_FOLDER_NAME<span class=\"token punctuation\">,</span> <span class=\"token string\">\"*\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> f <span class=\"token keyword\">in</span> folders<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> f<span class=\"token punctuation\">.</span>rsplit<span class=\"token punctuation\">(</span><span class=\"token string\">\"/\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> labels_to_keep<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n            shutil<span class=\"token punctuation\">.</span>rmtree<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">except</span> OSError <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Error: %s : %s\"</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">,</span> e<span class=\"token punctuation\">.</span>strerror<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Doing the same to test data.</span>\nfolders <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">.</span>glob<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>DEVANAGARI_DATA_FOLDER<span class=\"token punctuation\">,</span> TEST_FOLDER_NAME<span class=\"token punctuation\">,</span> <span class=\"token string\">\"*\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> f <span class=\"token keyword\">in</span> folders<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> f<span class=\"token punctuation\">.</span>rsplit<span class=\"token punctuation\">(</span><span class=\"token string\">\"/\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> labels_to_keep<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n            shutil<span class=\"token punctuation\">.</span>rmtree<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">except</span> OSError <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Error: %s : %s\"</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">,</span> e<span class=\"token punctuation\">.</span>strerror<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"dataset-and-model-parameters\" style=\"position:relative;\"><a href=\"#dataset-and-model-parameters\" aria-label=\"dataset and model parameters permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Dataset and Model Parameters</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">RANDOM_SEED <span class=\"token operator\">=</span> <span class=\"token number\">42</span>\n\n<span class=\"token comment\"># Data parameters</span>\nIMG_HEIGHT <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nIMG_WIDTH <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nVALIDATION_SPLIT <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>\n\n<span class=\"token comment\"># Model parameters</span>\nBATCH_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\nKERNEL_SIZE <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\nMAX_POOLING_SIZE <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\nDROPOUT <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span>\n\nnum_classes <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>labels_to_keep<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">classes <span class=\"token operator\">=</span> labels_to_keep\nclasses_to_output_class_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"digit_0\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"0\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_1\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_2\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_3\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"3\"</span><span class=\"token punctuation\">,</span> \n    <span class=\"token string\">\"digit_4\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_5\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_6\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"6\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_7\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"7\"</span><span class=\"token punctuation\">,</span> \n    <span class=\"token string\">\"digit_8\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"digit_9\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"9\"</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Gathering training dataset...\"</span><span class=\"token punctuation\">)</span>\ntrain_dataset <span class=\"token operator\">=</span> image_dataset_from_directory<span class=\"token punctuation\">(</span>\n    os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>DEVANAGARI_DATA_FOLDER<span class=\"token punctuation\">,</span> TRAIN_FOLDER_NAME<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    labels<span class=\"token operator\">=</span><span class=\"token string\">\"inferred\"</span><span class=\"token punctuation\">,</span>\n    label_mode<span class=\"token operator\">=</span><span class=\"token string\">\"int\"</span><span class=\"token punctuation\">,</span>\n    class_names<span class=\"token operator\">=</span>classes<span class=\"token punctuation\">,</span>\n    color_mode<span class=\"token operator\">=</span><span class=\"token string\">\"grayscale\"</span><span class=\"token punctuation\">,</span>\n    batch_size<span class=\"token operator\">=</span>BATCH_SIZE<span class=\"token punctuation\">,</span>\n    image_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>IMG_HEIGHT<span class=\"token punctuation\">,</span> IMG_WIDTH<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    seed<span class=\"token operator\">=</span>RANDOM_SEED<span class=\"token punctuation\">,</span>\n    validation_split<span class=\"token operator\">=</span>VALIDATION_SPLIT<span class=\"token punctuation\">,</span>\n    subset<span class=\"token operator\">=</span><span class=\"token string\">\"training\"</span><span class=\"token punctuation\">,</span>\n    interpolation<span class=\"token operator\">=</span><span class=\"token string\">\"bilinear\"</span><span class=\"token punctuation\">,</span>\n    follow_links<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n    crop_to_aspect_ratio<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Gathering validation dataset...\"</span><span class=\"token punctuation\">)</span>\nval_dataset <span class=\"token operator\">=</span> image_dataset_from_directory<span class=\"token punctuation\">(</span>\n    os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>DEVANAGARI_DATA_FOLDER<span class=\"token punctuation\">,</span> TRAIN_FOLDER_NAME<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    labels<span class=\"token operator\">=</span><span class=\"token string\">\"inferred\"</span><span class=\"token punctuation\">,</span>\n    label_mode<span class=\"token operator\">=</span><span class=\"token string\">\"int\"</span><span class=\"token punctuation\">,</span>\n    class_names<span class=\"token operator\">=</span>classes<span class=\"token punctuation\">,</span>\n    color_mode<span class=\"token operator\">=</span><span class=\"token string\">\"grayscale\"</span><span class=\"token punctuation\">,</span>\n    batch_size<span class=\"token operator\">=</span>BATCH_SIZE<span class=\"token punctuation\">,</span>\n    image_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>IMG_HEIGHT<span class=\"token punctuation\">,</span> IMG_WIDTH<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    seed<span class=\"token operator\">=</span>RANDOM_SEED<span class=\"token punctuation\">,</span>\n    validation_split<span class=\"token operator\">=</span>VALIDATION_SPLIT<span class=\"token punctuation\">,</span>\n    subset<span class=\"token operator\">=</span><span class=\"token string\">\"validation\"</span><span class=\"token punctuation\">,</span>\n    interpolation<span class=\"token operator\">=</span><span class=\"token string\">\"bilinear\"</span><span class=\"token punctuation\">,</span>\n    follow_links<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n    crop_to_aspect_ratio<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Gathering test dataset...\"</span><span class=\"token punctuation\">)</span>\ntest_dataset <span class=\"token operator\">=</span> image_dataset_from_directory<span class=\"token punctuation\">(</span>\n    os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>DEVANAGARI_DATA_FOLDER<span class=\"token punctuation\">,</span> TEST_FOLDER_NAME<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    labels<span class=\"token operator\">=</span><span class=\"token string\">\"inferred\"</span><span class=\"token punctuation\">,</span>\n    label_mode<span class=\"token operator\">=</span><span class=\"token string\">\"int\"</span><span class=\"token punctuation\">,</span>\n    class_names<span class=\"token operator\">=</span>classes<span class=\"token punctuation\">,</span>\n    color_mode<span class=\"token operator\">=</span><span class=\"token string\">\"grayscale\"</span><span class=\"token punctuation\">,</span>\n    batch_size<span class=\"token operator\">=</span>BATCH_SIZE<span class=\"token punctuation\">,</span>\n    image_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>IMG_HEIGHT<span class=\"token punctuation\">,</span> IMG_WIDTH<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    seed<span class=\"token operator\">=</span>RANDOM_SEED<span class=\"token punctuation\">,</span>\n    validation_split<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># None, so that we get all the data.</span>\n    subset<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n    interpolation<span class=\"token operator\">=</span><span class=\"token string\">\"bilinear\"</span><span class=\"token punctuation\">,</span>\n    follow_links<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n    crop_to_aspect_ratio<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Gathering training dataset...\nFound 17000 files belonging to 10 classes.\nUsing 15300 files for training.\nMetal device set to: Apple M1\nGathering validation dataset...\n\n\n2022-02-23 23:32:59.540309: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n2022-02-23 23:32:59.540429: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined>)\n\n\nFound 17000 files belonging to 10 classes.\nUsing 1700 files for validation.\nGathering test dataset...\nFound 3000 files belonging to 10 classes.</code></pre></div>\n<p>The tensorflow Dataset object automatically performs ordinal encoding on the labels and so, we are creating our own ordinal encoding and storing it in the variable <code class=\"language-text\">labels_to_class_names</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">class_names_to_labels <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>cls_name<span class=\"token punctuation\">,</span> lbl<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> cls_name<span class=\"token punctuation\">,</span> lbl <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>classes<span class=\"token punctuation\">,</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>classes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nlabels_to_class_names <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span> v <span class=\"token keyword\">in</span> class_names_to_labels<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>labels_to_class_names<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">{0: 'digit_0', 1: 'digit_1', 2: 'digit_2', 3: 'digit_3', 4: 'digit_4', 5: 'digit_5', 6: 'digit_6', 7: 'digit_7', 8: 'digit_8', 9: 'digit_9'}</code></pre></div>\n<h3 id=\"look-at-the-data\" style=\"position:relative;\"><a href=\"#look-at-the-data\" aria-label=\"look at the data permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Look at the data</h3>\n<p>Let us take a look at the data after it has been stored as a tensorflow tf.Data.Dataset object.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Take a look at the input data</span>\nrows <span class=\"token operator\">=</span> <span class=\"token number\">2</span>\ncolumns <span class=\"token operator\">=</span> <span class=\"token number\">3</span>\nfig <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nj <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n<span class=\"token keyword\">for</span> images<span class=\"token punctuation\">,</span> labels <span class=\"token keyword\">in</span> train_dataset<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> l <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        fig<span class=\"token punctuation\">.</span>add_subplot<span class=\"token punctuation\">(</span>rows<span class=\"token punctuation\">,</span> columns<span class=\"token punctuation\">,</span> j<span class=\"token punctuation\">)</span>\n        plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">,</span> vmin<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> vmax<span class=\"token operator\">=</span><span class=\"token number\">255</span><span class=\"token punctuation\">)</span>\n        plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>labels_to_class_names<span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        j <span class=\"token operator\">+=</span> <span class=\"token number\">1</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 592px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3a8b3aae0695dabd7f3dac310e181b31/694d5/output_13_2.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 75.49999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAQMA/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAABqEh08f/EABkQAAIDAQAAAAAAAAAAAAAAAAEDAhETAP/aAAgBAQABBQIQboFtAzeOphdGLbzdf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EAB0QAAIDAAIDAAAAAAAAAAAAAAERAAIxEiEiYXH/2gAIAQEABj8CPidPbhQtnTMKrZezMIR17LJrjrhRK+z/xAAbEAACAgMBAAAAAAAAAAAAAAABEQAhMWFxUf/aAAgBAQABPyEMxRV4XBvtAScNwFgY2YA+2VBi5AaVCJi632XjYsT/AP/aAAwDAQACAAMAAAAQwM//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAEBAQACAwEAAAAAAAAAAAABIREAMUFRcaH/2gAIAQEAAT8QWPTE6lGnjBD11OULxpQXS82OBI98rVg0L+ziScmTUx1GiP3gd1YdO3Inh1wqrxcoes2c/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"random devanagari digits\"\n        title=\"random devanagari digits\"\n        src=\"/static/3a8b3aae0695dabd7f3dac310e181b31/694d5/output_13_2.jpg\"\n        srcset=\"/static/3a8b3aae0695dabd7f3dac310e181b31/e07e9/output_13_2.jpg 200w,\n/static/3a8b3aae0695dabd7f3dac310e181b31/066f9/output_13_2.jpg 400w,\n/static/3a8b3aae0695dabd7f3dac310e181b31/694d5/output_13_2.jpg 592w\"\n        sizes=\"(max-width: 592px) 100vw, 592px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"data-augmentation-and-normalisation\" style=\"position:relative;\"><a href=\"#data-augmentation-and-normalisation\" aria-label=\"data augmentation and normalisation permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Data Augmentation and Normalisation</h3>\n<h4 id=\"normalisation\" style=\"position:relative;\"><a href=\"#normalisation\" aria-label=\"normalisation permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Normalisation</h4>\n<p>The values of pixels in the images range from <code class=\"language-text\">[0, 255]</code>.</p>\n<p>We should normalize the values to be in the <code class=\"language-text\">[0, 1]</code> range.</p>\n<p>The purpose of Normalisation is to make values measured on different scales to be all \"squished\" or \"expanded\" to a common scale/range such as <code class=\"language-text\">[0, 1]</code>.\nThis ensures that each variable in the data is given an equal importance and no variable influences the model parameters more than any other purely because it's values are larger.</p>\n<p>We will perform the normalization using <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling\"><code>tf.keras.layers.Rescaling</code></a>.</p>\n<h4 id=\"augmentation\" style=\"position:relative;\"><a href=\"#augmentation\" aria-label=\"augmentation permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Augmentation</h4>\n<p>Augmenting the data allows us to ensure that the model doesn't just learn something that's common for the entire class, but has no meaning when it comes to classification.</p>\n<p>For example, consider a dataset with blue cars and red cars.</p>\n<p>If all the blue cars are facing to the right and all red cars are facing left, then the model will end up being influenced by the orientation of the car in the image, thus producing incorrect predications when you ask the model to predict, say, the color of a blue car facing to the left.</p>\n<p>By performing augmentations such as Flipping, Rotations, Zooming, Shearing, Translations etc, we prevent the model from learning/memorizing features which are irrelevant.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Scale images to the [0, 1] range</span>\nnormalization_layer <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Rescaling<span class=\"token punctuation\">(</span><span class=\"token number\">1.</span> <span class=\"token operator\">/</span> <span class=\"token number\">255</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Data Augmentations</span>\n<span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span><span class=\"token string\">'/CPU:0'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    data_augmentation_layers <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n        <span class=\"token punctuation\">[</span>\n            layers<span class=\"token punctuation\">.</span>RandomZoom<span class=\"token punctuation\">(</span><span class=\"token number\">0.05</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            layers<span class=\"token punctuation\">.</span>RandomTranslation<span class=\"token punctuation\">(</span><span class=\"token number\">0.05</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.05</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"prefetch-and-caching\" style=\"position:relative;\"><a href=\"#prefetch-and-caching\" aria-label=\"prefetch and caching permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Prefetch and Caching</h3>\n<p>Learn about tf.data.Dataset Prefetching here: <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch\">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch</a>\nLearn about tf.data.Dataset Caching here: <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache\">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># prefetching and caching data to improve performance.</span>\nAUTOTUNE <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>AUTOTUNE\n\ntrain_ds <span class=\"token operator\">=</span> train_dataset<span class=\"token punctuation\">.</span>cache<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>prefetch<span class=\"token punctuation\">(</span>buffer_size<span class=\"token operator\">=</span>AUTOTUNE<span class=\"token punctuation\">)</span>\nval_ds <span class=\"token operator\">=</span> val_dataset<span class=\"token punctuation\">.</span>cache<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>prefetch<span class=\"token punctuation\">(</span>buffer_size<span class=\"token operator\">=</span>AUTOTUNE<span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"checking-data-augmentation\" style=\"position:relative;\"><a href=\"#checking-data-augmentation\" aria-label=\"checking data augmentation permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Checking Data Augmentation</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">rows <span class=\"token operator\">=</span> <span class=\"token number\">3</span>\ncolumns <span class=\"token operator\">=</span> <span class=\"token number\">4</span>\n<span class=\"token keyword\">for</span> images<span class=\"token punctuation\">,</span> _ <span class=\"token keyword\">in</span> train_dataset<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">,</span> vmin<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> vmax<span class=\"token operator\">=</span><span class=\"token number\">255</span><span class=\"token punctuation\">)</span>\n    fig <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span><span class=\"token string\">'/CPU:0'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            augmented_images <span class=\"token operator\">=</span> data_augmentation_layers<span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">)</span>\n        fig<span class=\"token punctuation\">.</span>add_subplot<span class=\"token punctuation\">(</span>rows<span class=\"token punctuation\">,</span> columns<span class=\"token punctuation\">,</span> i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))</span>\n        plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>augmented_images<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">,</span> vmin<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> vmax<span class=\"token operator\">=</span><span class=\"token number\">255</span><span class=\"token punctuation\">)</span>\n        plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">\"off\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 251px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d747c2d6661b8115c924f97e8e1ef9c1/0ce01/output_19_0.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 99%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAIDAAAAAAAAAAAAAAAAAAIEAQUG/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAABnQta4MjpoBAH/8QAGxAAAgMAAwAAAAAAAAAAAAAAAgMAAQQREhP/2gAIAQEAAQUCYHppeNLBZlxqAmFWR9zpa4WdZMvMspWRNT//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAkEAABAwIEBwAAAAAAAAAAAAABAAIRAxIEIVGBIjIzYYKRof/aAAgBAQAGPwKrNRzAAFLMSXnSVzH2qjWZkEEjZdM7q0xPZX53agriuPkVk36v/8QAHBABAAICAwEAAAAAAAAAAAAAAQARMUFRYZFx/9oACAEBAAE/IRM4gjQQbYNIhbvPyhe0IZSNSeJZVXZccMK2SZx9pC0nqf/aAAwDAQACAAMAAAAQ8wc8/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAHhABAAICAgMBAAAAAAAAAAAAAQARIUExUWFxkfD/2gAIAQEAAT8QzrtSozdszZhDx2UxqS9ug8xS2kUANbpv7HcB2oJ9lXibayWGLNwVzUocFaYbQ/FMOPcpgjn8M//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"first devanagari digit\"\n        title=\"first devanagari digit\"\n        src=\"/static/d747c2d6661b8115c924f97e8e1ef9c1/0ce01/output_19_0.jpg\"\n        srcset=\"/static/d747c2d6661b8115c924f97e8e1ef9c1/e07e9/output_19_0.jpg 200w,\n/static/d747c2d6661b8115c924f97e8e1ef9c1/0ce01/output_19_0.jpg 251w\"\n        sizes=\"(max-width: 251px) 100vw, 251px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 572px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/aa8512a3f884945907fef4a6b0d6bfbe/8d13f/output_19_1.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 104%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAVABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAEEAgP/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHTYPBRxAzg/8QAGxAAAgMAAwAAAAAAAAAAAAAAAQIABBEDEhT/2gAIAQEAAQUC8rwVWEai5IqvBVfTS5CerQBo6tv/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAeEAABAwQDAAAAAAAAAAAAAAAAAiIzASExMgOBof/aAAgBAQAGPwJT8iX6kgp9LiH6kop2TjfW3pIro//EAB4QAAIDAAIDAQAAAAAAAAAAAAERACExQWFRkaHR/9oACAEBAAE/IRcVpxkPcSV5jR+ICNQBVkBKiR9x4+KnqaqhHMCsRq2DpP/aAAwDAQACAAMAAAAQ888A/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAHRABAQADAQADAQAAAAAAAAAAAREAITFBUWGBkf/aAAgBAQABPxClIIHYheEnvtwBS2O25esvuIyd9gj+BMPpCIslvE2/bvFY2krZXrLx5juRfCk/DE34U76ry7fvCUVj6Ku17PrN3YDFJ+Gf/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"augmented digits\"\n        title=\"augmented digits\"\n        src=\"/static/aa8512a3f884945907fef4a6b0d6bfbe/8d13f/output_19_1.jpg\"\n        srcset=\"/static/aa8512a3f884945907fef4a6b0d6bfbe/e07e9/output_19_1.jpg 200w,\n/static/aa8512a3f884945907fef4a6b0d6bfbe/066f9/output_19_1.jpg 400w,\n/static/aa8512a3f884945907fef4a6b0d6bfbe/8d13f/output_19_1.jpg 572w\"\n        sizes=\"(max-width: 572px) 100vw, 572px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"creating-the-model\" style=\"position:relative;\"><a href=\"#creating-the-model\" aria-label=\"creating the model permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Creating the Model</h3>\n<p>First, we'll add the <code class=\"language-text\">data_augmentation_layers</code> and the <code class=\"language-text\">normalization_layer</code>, following which we'll create a convolutional neural network.</p>\n<p>Learn more about CNNs here: <a href=\"https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\">https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span>\n        data_augmentation_layers<span class=\"token punctuation\">,</span>\n        normalization_layer<span class=\"token punctuation\">,</span>\n        layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span>KERNEL_SIZE<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        layers<span class=\"token punctuation\">.</span>MaxPooling2D<span class=\"token punctuation\">(</span>pool_size<span class=\"token operator\">=</span>MAX_POOLING_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span>KERNEL_SIZE<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        layers<span class=\"token punctuation\">.</span>MaxPooling2D<span class=\"token punctuation\">(</span>pool_size<span class=\"token operator\">=</span>MAX_POOLING_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>DROPOUT<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>num_classes<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"softmax\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"compiling-and-building-model\" style=\"position:relative;\"><a href=\"#compiling-and-building-model\" aria-label=\"compiling and building model permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Compiling and Building Model</h3>\n<p>Note that we are using Categorical Crossentropy as the loss function, and this is well suited for categorical output data.\nRead more here: <a href=\"https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression\">https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>SparseCategoricalCrossentropy<span class=\"token punctuation\">(</span>from_logits<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>build<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">,</span> IMG_HEIGHT<span class=\"token punctuation\">,</span> IMG_WIDTH<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n sequential (Sequential)     (32, 32, 32, 1)           0         \n                                                                 \n rescaling (Rescaling)       (32, 32, 32, 1)           0         \n                                                                 \n conv2d (Conv2D)             (32, 30, 30, 32)          320       \n                                                                 \n max_pooling2d (MaxPooling2D  (32, 15, 15, 32)         0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (32, 13, 13, 64)          18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (32, 6, 6, 64)           0         \n 2D)                                                             \n                                                                 \n dropout (Dropout)           (32, 6, 6, 64)            0         \n                                                                 \n flatten (Flatten)           (32, 2304)                0         \n                                                                 \n dense (Dense)               (32, 128)                 295040    \n                                                                 \n dense_1 (Dense)             (32, 10)                  1290      \n                                                                 \n=================================================================\nTotal params: 315,146\nTrainable params: 315,146\nNon-trainable params: 0\n_________________________________________________________________</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">epochs <span class=\"token operator\">=</span> <span class=\"token number\">15</span>\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\n    train_dataset<span class=\"token punctuation\">,</span>\n    validation_data<span class=\"token operator\">=</span>val_dataset<span class=\"token punctuation\">,</span>\n    epochs<span class=\"token operator\">=</span>epochs\n<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch 1/15\n\n\n2022-02-23 23:33:01.336773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n\n\n479/479 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.8952\n\n2022-02-23 23:33:09.665198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n\n\n479/479 [==============================] - 9s 18ms/step - loss: 0.3290 - accuracy: 0.8952 - val_loss: 0.0485 - val_accuracy: 0.9865\nEpoch 2/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0899 - accuracy: 0.9727 - val_loss: 0.0420 - val_accuracy: 0.9871\nEpoch 3/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0578 - accuracy: 0.9808 - val_loss: 0.0216 - val_accuracy: 0.9924\nEpoch 4/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0171 - val_accuracy: 0.9935\nEpoch 5/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.0191 - val_accuracy: 0.9918\nEpoch 6/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0345 - accuracy: 0.9892 - val_loss: 0.0086 - val_accuracy: 0.9976\nEpoch 7/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.0097 - val_accuracy: 0.9965\nEpoch 8/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.0110 - val_accuracy: 0.9959\nEpoch 9/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0142 - val_accuracy: 0.9953\nEpoch 10/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.0104 - val_accuracy: 0.9953\nEpoch 11/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0126 - val_accuracy: 0.9965\nEpoch 12/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0097 - val_accuracy: 0.9971\nEpoch 13/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0081 - val_accuracy: 0.9971\nEpoch 14/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0321 - val_accuracy: 0.9912\nEpoch 15/15\n479/479 [==============================] - 8s 17ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0176 - val_accuracy: 0.9941</code></pre></div>\n<h3 id=\"measuring-performance-on-training-and-test-data\" style=\"position:relative;\"><a href=\"#measuring-performance-on-training-and-test-data\" aria-label=\"measuring performance on training and test data permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Measuring Performance on Training and Test Data</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span>\nval_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span>\n\nloss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span>\nval_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span>\n\nepochs_range <span class=\"token operator\">=</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> epochs <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\nfig <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nfig<span class=\"token punctuation\">.</span>add_subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nsns<span class=\"token punctuation\">.</span>lineplot<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span>epochs_range<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>acc<span class=\"token punctuation\">,</span> legend<span class=\"token operator\">=</span><span class=\"token string\">'brief'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Training Accuracy'</span><span class=\"token punctuation\">)</span>\nsns<span class=\"token punctuation\">.</span>lineplot<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span>epochs_range<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>val_acc<span class=\"token punctuation\">,</span> legend<span class=\"token operator\">=</span><span class=\"token string\">'brief'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Validation Accuracy'</span><span class=\"token punctuation\">)</span>\n\nfig<span class=\"token punctuation\">.</span>add_subplot<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\nsns<span class=\"token punctuation\">.</span>lineplot<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span>epochs_range<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>loss<span class=\"token punctuation\">,</span> legend<span class=\"token operator\">=</span><span class=\"token string\">'brief'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Training Loss'</span><span class=\"token punctuation\">)</span>\nsns<span class=\"token punctuation\">.</span>lineplot<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span>epochs_range<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>val_loss<span class=\"token punctuation\">,</span> legend<span class=\"token operator\">=</span><span class=\"token string\">'brief'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Validation Loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2b275f66f87a9c6104288b586b647feb/f84cf/output_26_0.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 34.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3gQH/8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQABBQJ//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQAGPwJ//8QAFhABAQEAAAAAAAAAAAAAAAAAABEh/9oACAEBAAE/Icisf//aAAwDAQACAAMAAAAQ88//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAEAAgMBAAAAAAAAAAAAAAABABEhQZGx/9oACAEBAAE/EFFnyAMu42bA5P/Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"model metrics graph\"\n        title=\"model metrics graph\"\n        src=\"/static/2b275f66f87a9c6104288b586b647feb/4b190/output_26_0.jpg\"\n        srcset=\"/static/2b275f66f87a9c6104288b586b647feb/e07e9/output_26_0.jpg 200w,\n/static/2b275f66f87a9c6104288b586b647feb/066f9/output_26_0.jpg 400w,\n/static/2b275f66f87a9c6104288b586b647feb/4b190/output_26_0.jpg 800w,\n/static/2b275f66f87a9c6104288b586b647feb/f84cf/output_26_0.jpg 880w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"metrics\" style=\"position:relative;\"><a href=\"#metrics\" aria-label=\"metrics permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Metrics</h3>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Data</th>\n<th align=\"center\">Accuracy</th>\n<th align=\"right\">Loss</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Training</td>\n<td align=\"center\">99.52%</td>\n<td align=\"right\">0.0139</td>\n</tr>\n<tr>\n<td align=\"left\">Validation</td>\n<td align=\"center\">99.65%</td>\n<td align=\"right\">0.0107</td>\n</tr>\n</tbody>\n</table>\n<!-- Training Accuracy: 99.52%\n\nValidation Accuracy: 99.65%\n\nTraining Loss: 0.0139\n\nValidation Loss: 0.0107 -->\n<p>We can see that the model's accuracy and validation accuracy quickly went up during and after the first epoch and then it saturated around epoch #10.</p>\n<p>Training and validation loss also fell dramatically after the second epoch, and reached a saturation around epoch #11.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Evaluate\"</span><span class=\"token punctuation\">)</span>\nresult <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>test_dataset<span class=\"token punctuation\">)</span>\nresult <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>metrics_names<span class=\"token punctuation\">,</span> result<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Evaluate\n94/94 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9953</code></pre></div>\n<h3 id=\"test-metrics\" style=\"position:relative;\"><a href=\"#test-metrics\" aria-label=\"test metrics permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Test Metrics</h3>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Data</th>\n<th align=\"center\">Accuracy</th>\n<th align=\"right\">Loss</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Test</td>\n<td align=\"center\">99.56%</td>\n<td align=\"right\">0.0189</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"overall-this-is-a-great-result-and-it-shows-that-the-model-has-generalized-properly-and-has-low-variance-while-having-high-bias\" style=\"position:relative;\"><a href=\"#overall-this-is-a-great-result-and-it-shows-that-the-model-has-generalized-properly-and-has-low-variance-while-having-high-bias\" aria-label=\"overall this is a great result and it shows that the model has generalized properly and has low variance while having high bias permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Overall this is a great result, and it shows that the model has generalized properly and has low variance, while having high bias.</h4>\n<h3 id=\"saving-the-model\" style=\"position:relative;\"><a href=\"#saving-the-model\" aria-label=\"saving the model permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>Saving the Model</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">MODEL_FOLDER <span class=\"token operator\">=</span> <span class=\"token string\">\"./models\"</span>\nHINDI_MNIST_FOLDER <span class=\"token operator\">=</span> <span class=\"token string\">\"hindi_mnist\"</span>\nMODEL_SAVE_FOLDER <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>MODEL_FOLDER<span class=\"token punctuation\">,</span> HINDI_MNIST_FOLDER<span class=\"token punctuation\">)</span>\nMODEL_SAVE_PATH <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>MODEL_FOLDER<span class=\"token punctuation\">,</span> HINDI_MNIST_FOLDER<span class=\"token punctuation\">,</span> <span class=\"token string\">\"model.h5\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># pickle files</span>\nCLASSES_PKL_FILE <span class=\"token operator\">=</span> <span class=\"token string\">\"classes.pickle\"</span>\nCLASSES_PKL_PATH <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>MODEL_SAVE_FOLDER<span class=\"token punctuation\">,</span> CLASSES_PKL_FILE<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>\n    MODEL_SAVE_PATH<span class=\"token punctuation\">,</span> overwrite<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> include_optimizer<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> save_format<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n    signatures<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> options<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> save_traces<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>CLASSES_PKL_PATH<span class=\"token punctuation\">,</span> <span class=\"token string\">'wb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n    pkl<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>classes<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">)</span>\n    pkl<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>labels_to_class_names<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Delete model and labels_to_class_names to check if we correctly saved the model by loading it from disk and re-evaluating on test data.</span>\n<span class=\"token keyword\">del</span> model\n<span class=\"token keyword\">del</span> classes\n<span class=\"token keyword\">del</span> labels_to_class_names</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pickle <span class=\"token keyword\">as</span> pkl\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> load_model</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> load_model<span class=\"token punctuation\">(</span>MODEL_SAVE_PATH<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>CLASSES_PKL_PATH<span class=\"token punctuation\">,</span> <span class=\"token string\">'rb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n    classes <span class=\"token operator\">=</span> pkl<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n    labels_to_class_names <span class=\"token operator\">=</span> pkl<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Evaluate\"</span><span class=\"token punctuation\">)</span>\nresult <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>test_dataset<span class=\"token punctuation\">)</span>\nresult <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>metrics_names<span class=\"token punctuation\">,</span> result<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Evaluate\n19/94 [=====>........................] - ETA: 0s - loss: 0.0088 - accuracy: 0.9984\n\n2022-02-23 23:35:04.809043: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n\n94/94 [==============================] - 1s 6ms/step - loss: 0.0242 - accuracy: 0.9953\n{'loss': 0.024181803688406944, 'accuracy': 0.9953333139419556}</code></pre></div>\n<h2 id=\"references-and-further-reading\" style=\"position:relative;\"><a href=\"#references-and-further-reading\" aria-label=\"references and further reading permalink\" class=\"custom-class before\"><svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path d=\"M14.851 11.923c-.179-.641-.521-1.246-1.025-1.749-1.562-1.562-4.095-1.563-5.657 0l-4.998 4.998c-1.562 1.563-1.563 4.095 0 5.657 1.562 1.563 4.096 1.561 5.656 0l3.842-3.841.333.009c.404 0 .802-.04 1.189-.117l-4.657 4.656c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-1.952-1.951-1.952-5.12 0-7.071l4.998-4.998c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464.493.493.861 1.063 1.105 1.672l-.787.784zm-5.703.147c.178.643.521 1.25 1.026 1.756 1.562 1.563 4.096 1.561 5.656 0l4.999-4.998c1.563-1.562 1.563-4.095 0-5.657-1.562-1.562-4.095-1.563-5.657 0l-3.841 3.841-.333-.009c-.404 0-.802.04-1.189.117l4.656-4.656c.975-.976 2.256-1.464 3.536-1.464 1.279 0 2.56.488 3.535 1.464 1.951 1.951 1.951 5.119 0 7.071l-4.999 4.998c-.975.976-2.255 1.464-3.535 1.464-1.28 0-2.56-.488-3.535-1.464-.494-.495-.863-1.067-1.107-1.678l.788-.785z\"/></svg></a>References and Further Reading</h2>\n<ol>\n<li>Dataset: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00389/DevanagariHandwrittenCharacterDataset.zip\">https://archive.ics.uci.edu/ml/machine-learning-databases/00389/DevanagariHandwrittenCharacterDataset.zip</a></li>\n<li>Tensorflow Rescaling documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling\">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling</a></li>\n<li>Tensorflow Dataset documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\">https://www.tensorflow.org/api_docs/python/tf/data/Dataset</a></li>\n<li>Convolutional Neural Networks: <a href=\"https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\">https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/</a></li>\n<li>Categorical CrossEntropy loss function <a href=\"https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression\">https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression</a></li>\n<li>Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [<a href=\"http://archive.ics.uci.edu/ml\">http://archive.ics.uci.edu/ml</a>]. Irvine, CA: University of California, School of Information and Computer Science.</li>\n</ol>","frontmatter":{"date":"February 24, 2022","slug":"/blog/hindi-mnist-recognizer","title":"Hindi (Devanagari Script) Digit Recognizer using Convolutional Neural Networks"}}},"pageContext":{"id":"ba34ea87-cf26-51f3-b65b-1dae753656ae","frontmatter__slug":"/blog/hindi-mnist-recognizer","__params":{"frontmatter__slug":"blog"}}},
    "staticQueryHashes": ["63159454"]}